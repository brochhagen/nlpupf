{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c6ca76",
   "metadata": {},
   "source": [
    "# Text summarization\n",
    "\n",
    "Approaches can be roughly categorized into *abstractive* and *extractive* summarization. Extractive summarization works more closely with the input given, *extracting* the most important sentence(s) from a text and making a summary out of that. Abstractive summarization tries to synthesize the text in a more holistic way, producing completely new sentences.\n",
    "\n",
    "The (extractive) summarization pipeline follows three steps\n",
    "\n",
    "1. Sentence scoring: Which sentences are the most important?\n",
    "2. Sentence selection: Which sentences out of 1 carry complementary information?\n",
    "3. Sentence reformulation: Which material can I reformulate / compress further?\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>Discussion.</b> Many approaches are frequency based. That is, they assume that the most important information in a text will appear more frequently in the text. Is this a reasonable assumption?\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6930e44",
   "metadata": {},
   "source": [
    "# ROUGE-N (Recall-Oriented Understudy for Gisting Evaluation)\n",
    "\n",
    "ROUGE-N is the n-gram recall between a candidate summary and a set of reference summaries. \n",
    "\n",
    "$$\\text{ROUGE-N}_{\\text{recall}} = \\frac{\\sum_{S \\in \\{ \\text{Reference Summaries} \\}}\\sum_{gram_n \\in S} \\text{Count}_{\\text{match}}(gram_n)}{\\sum_{S \\in \\{ \\text{Reference Summaries} \\}}\\sum_{gram_n \\in S} \\text{Count}(gram_n)},$$\n",
    "\n",
    "where $n$ is the length of the n-gram, and $\\text{Count}_{\\text{match}}$ is the maximum number of n-grams co-occurring in a candidate summary and a reference summary $S$.\n",
    "\n",
    "ROUGE-L is based on the longest common subsequence shared between the reference and the candidate summary (N.B.: the common words are not necessarily consecutive, just in the same sequence).\n",
    "\n",
    "$$\\text{ROUGE-L} = \\frac{LCS(S,X)}{m},$$\n",
    "\n",
    "where $m$ is the length of the reference summary. So if *Government reduces taxes next Monday* is the reference summary and our candidate is *The goverment reduces income taxes starting the following week*, we have a LCS of with \"government reduces taxes\", so 3 out of a reference summary of 5 (i.e., a ROUGE-L of 0.6).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>Discussion.</b> What are the advantages and weaknesses of ROUGE-N and ROUGE-L?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed38c0",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "# For task 2/3\n",
    "\n",
    "Implement an extractive summarization model that uses Lead-5 together with at least two linguistically motivated compressive capabilities (e.g., with two tree-trimming rules), and compare it to either (i) a fully abstractive summarization model or (ii) another extractive model that uses regression for importance prediction. Explain the main features of your implementation. Evaluate it using ROUGE-L on both the English MLSUM subset and a non-English subset. Discuss the quality of the summarizations in connection to your results within each subset and across.\n",
    "\n",
    "\n",
    "# For preparation\n",
    "Read sections 1 and 2.3 of \"Recent Advances in Document Summarization\" and then the full \"MLSUM: The Multilingual Summarization Corpus\" paper\n",
    "https://wanxiaojun.github.io/summ_survey_draft.pdf\n",
    "https://aclanthology.org/2020.emnlp-main.647.pdf\n",
    "\n",
    "# For in class\n",
    "\n",
    "Prepare MLSUM English data to build a model that uses Lead-2, evaluate it using ROUGE-2; and another using regression with importance prediction\n",
    "\n",
    "\n",
    "regression models for importance prediction [209, 53, 72] -> can we implement this?\n",
    "We could regress on the ground truth frequencies to \"to learn a regression model to\n",
    "minimize the distance between the ground truth bigram\n",
    "frequency statistics in the reference summary and the\n",
    "estimated frequency [97]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf46c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpupf",
   "language": "python",
   "name": "nlpupf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
