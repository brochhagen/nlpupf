{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b32882",
   "metadata": {},
   "source": [
    "Open in colab: https://colab.research.google.com/github/brochhagen/nlpupf/blob/main/material/2026q2/session02/session0202-spaCyIntro.ipynb\n",
    "\n",
    "# spaCy demo\n",
    "\n",
    "This document serves as a live demo of some of the basic features of spaCy. The exercises are from the [spaCy 101 tutorial](https://spacy.io/usage/spacy-101). Check it out for solutions.\n",
    "\n",
    "## Getting started\n",
    "\n",
    "**Ex. 1:** Use `spacy.blank` to create a blank English (\"en\") nlp object. Create a doc and print its text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7086d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy\n",
    "import ____\n",
    "\n",
    "# Create the English nlp object\n",
    "nlp = ____\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "\n",
    "# Print the document text\n",
    "print(____.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa775ba6",
   "metadata": {},
   "source": [
    "**Ex. 2:** Use `spacy.blank` to create a blank German (\"de\") nlp object. Create a doc and print its text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy\n",
    "import ____\n",
    "\n",
    "# Create the German nlp object\n",
    "nlp = ____\n",
    "\n",
    "# Process a text (this is German for: \"Kind regards!\")\n",
    "doc = nlp(\"Liebe Grüße!\")\n",
    "\n",
    "# Print the document text\n",
    "print(____.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d1e9f",
   "metadata": {},
   "source": [
    "**Ex 3.:** Explain the spaCy related processing block from last session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5dda6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---***--- This snippet reads in a text from a URL ---***---\n",
    "\n",
    "import urllib.request #for opening/reading URLs\n",
    "book_url = 'https://www.gutenberg.org/cache/epub/1727/pg1727.txt' #URL of book we want to read in\n",
    "\n",
    "book_text = urllib.request.urlopen(book_url) #open URL as \"book_text\"\n",
    "book_text = book_text.read()                 #returns all bytes from \"book_text\" \n",
    "book_text = book_text.decode(\"utf-8\")        #decode as UTF-8\n",
    "# ---***--- ---***--- ---***--- ---***--- ---***---\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#---***--- start of spaCy related processing ---***---\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "doc = nlp(book_text)\n",
    "\n",
    "words = [token.text\n",
    "         for token in doc\n",
    "         if not token.is_stop and not token.is_punct]\n",
    "\n",
    "nouns = [token.text\n",
    "         for token in doc\n",
    "         if (not token.is_stop and\n",
    "             not token.is_punct and\n",
    "             token.pos_ == \"NOUN\")]\n",
    "\n",
    "# five most common tokens\n",
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(5)\n",
    "\n",
    "# five most common noun tokens\n",
    "noun_freq = Counter(nouns)\n",
    "common_nouns = noun_freq.most_common(5)\n",
    "# ---***--- end of spaCy related processing ---***---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
