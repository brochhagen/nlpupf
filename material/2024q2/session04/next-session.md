---
output:
  pdf_document: default
  html_document: default
urlcolor: blue
---
# NLP session 04: Preparation for next session
 * If you don't know or don't remember how to [multiply matrices](https://www.khanacademy.org/math/precalculus/x9e81a4f98389efdf:matrices/x9e81a4f98389efdf:multiplying-matrices-by-matrices/a/multiplying-matrices) or [vectors with matrices](https://mbernste.github.io/posts/matrix_vector_mult/) make sure to look it up.
 * Watch the first lecture of [Neural Networks: Zero to Hero](https://karpathy.ai/zero-to-hero.html).
 
### Recommended

 * Read Yoav Goldberg's [A Primer on Neural Network Models for Natural Language Processing](https://arxiv.org/abs/1510.00726), at least until page 35

### Optional

There are four topics you could introduce next week. This would count toward your in-class participation grade. If you want to present one of them, announce this on this week's forum on Aula Global. In this way others will know that the topic is already taken. 

  1. Explain matrix and vector multiplication through brief examples and exercises
  2. Walk the class through the output of [cell 319 of the notebook that accompanies the first Zero to Hero lecture](https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/micrograd/micrograd_lecture_second_half_roughly.ipynb). What is being depicted? How is this calculated? This counts for double credit
  3. Walk the class through the input of [cell 592 of the notebook that accompanies the first Zero to Hero lecture](https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/micrograd/micrograd_lecture_second_half_roughly.ipynb). What does this class characterize? Explain its components. This counts for double credit.
  4. Based on the first lecture of [Neural Networks: Zero to Hero](https://karpathy.ai/zero-to-hero.html): What is a loss? What is gradient descent? What role does the gradient play in all of this? Answer this question by explaining what the cells from 666 onward are doing 
   
